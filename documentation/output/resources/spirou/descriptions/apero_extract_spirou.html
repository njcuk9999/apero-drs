


<!doctype html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Extraction &#8212; APERO 0.8.001 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/bizstyle.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/images/fonta/css/font-awesome.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/apero.css" />
    
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
    <link rel="stylesheet" href="_static/images/fonta/css/font-awesome.min.css">



    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <!--[if lt IE 9]>
    <script src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
    <style>
      table.right { float: left; margin-left: 20px; }
      table.right td { border: 1px solid #ccc; }
      
    </style>
    <script>
      // intelligent scrolling of the sidebar content
      $(window).scroll(function() {
        var sb = $('.sphinxsidebarwrapper');
        var win = $(window);
        var sbh = sb.height();
        var offset = $('.sphinxsidebar').position()['top'];
        var wintop = win.scrollTop();
        var winbot = wintop + win.innerHeight();
        var curtop = sb.position()['top'];
        var curbot = curtop + sbh;
        // does sidebar fit in window?
        if (sbh < win.innerHeight()) {
          // yes: easy case -- always keep at the top
          sb.css('top', $u.min([$u.max([0, wintop - offset - 10]),
                                $(document).height() - sbh - 200]));
        } else {
          // no: only scroll if top/bottom edge of sidebar is at
          // top/bottom edge of window
          if (curtop > wintop && curbot > winbot) {
            sb.css('top', $u.max([wintop - offset - 10, 0]));
          } else if (curtop < wintop && curbot < winbot) {
            sb.css('top', $u.min([winbot - sbh - offset - 20,
                                  $(document).height() - sbh - 200]));
          }
        }
      });
    </script>

  </head><body>
<div class="pageheader">

  <ul>
    <li><a title="Home" href="../../../index.html">
        <i class="fa fa-home fa-3x" aria-hidden="true"></i></a></li>
    <li><a title="install" href="../../../user/general/installation.html">
        <i class="fa fa-cog fa-3x" aria-hidden="true"></i></a></li>
    <li><a title="github" href="https://github.com/njcuk9999/apero-drs">
        <i class="fa fa-git-square fa-3x" aria-hidden="true"></i></a></li>
    <li><a title="download documentation" href="../../../apero-docs.pdf">
        <i class="fa fa-download fa-3x" aria-hidden="true"></i></a></li>
    <li><a title="download paper" href="https://ui.adsabs.harvard.edu/abs/2022PASP..134k4509C">
        <i class="fa fa-file-pdf-o fa-3x" aria-hidden="true"></i></a></li>
    <li><a title="UdeM" href="http://apero.exoplanets.ca/main/misc/udem.html">
        <i class="fa fa-university fa-3x" aria-hidden="true"></i></a></li>
  </ul>
    <div>
    <a href="../../../index.html">
      <img src="../../../_static/images/apero_logo.png" alt="APERO" />
    </a>
    <br>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A PipelinE to Reduce Observations
    </div>

</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">APERO 0.8.001 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Extraction</a></li> 
      </ul>
    </div>

    <div class="document">
      <div class="documentwrapper">
          <div class="body" role="main">
            
  <section id="extraction">
<h1>Extraction<a class="headerlink" href="#extraction" title="Permalink to this heading">¶</a></h1>
<p>The extraction recipe takes any preprocessed file (as many as given by the user but in general just one single file).
The files are combined (if requested) and are calibrated using our standard image calibration technique. Once
calibrated, the correct (closest in time) order profile (<cite>ORDERP</cite>), positions of the orders (<cite>LOCO</cite>), <cite>SHAPELOCAL</cite>,
shape reference (x and y maps), and wavelength solution are loaded for each fiber (AB, A, B, and C). The order profiles
and input image are transformed to the reference FP grid using the affine transformation, and using the shape x and y
maps the image is corrected for the slicer geometry, the tilt and the bending due to the echelle orders.</p>
<p>The extraction recipe then extracts the flux (using optimal extraction), calculates the barycentric correction,
corrects contamination from the reference fiber (if an FP is present in the reference fiber), corrects for the flat,
corrects for the thermal contribution and generates the 1D spectrum.</p>
<section id="optimal-extraction">
<h2>Optimal extraction<a class="headerlink" href="#optimal-extraction" title="Permalink to this heading">¶</a></h2>
<p>Once the image and the order profile (from localization) have been corrected for the slicer geometry and curvature of
the echelle orders we extract out the combined flux in the science channels (fibers A and B) to create a fiber AB,
as well as extracting out the flux in A and B (for polarization work) and C separately (for the reference fiber
calibrations). As the orders are already straightened we use just the localization coefficient value at the center of
the image to extract vertically along each order. We then divide the image by the order profile to provide a weighting
across the order (i.e., an optimal extraction, Horne et al. 1986}). The final step of the optimal extraction is to sum
vertically across the columns accounting for cosmic rays by using a sigma clip <span class="math notranslate nohighlight">\(|flux|&gt;10\sigma\)</span> away from the
median value for that column. This creates our <cite>E2DS</cite> (extracted 2D spectrum) and for SPIRou, this leads to images
with 49 orders and 4088 pixels along the orders.</p>
</section>
<section id="berv-correction">
<h2>BERV correction<a class="headerlink" href="#berv-correction" title="Permalink to this heading">¶</a></h2>
<p>Ideally, any stellar spectrum observed would be measured from a point stationary with respect to the barycenter of the
Solar System (Wright et al. 2014). However, ground-based observations are subject to: the orbit of the Earth, the
rotation of the Earth, precession and other Earth motions, and to a lesser extent gravitation time dilation,
leap-second offsets, and factors affecting the star itself (i.e., parallax, proper motions, etc). We use the term BERV
(Barycentric Earth Radial Velocity) hereinafter to collect all these terms into a single measurement which can be used
to correct a specific spectrum at a specific point in time. We calculate the BERV using the barycorrpy package, which
uses the astrometric parameters fed in at the preprocessing level. The calculation from barycorrpy includes the
estimate for the BERV itself and the corrected or barycentric Julian Date (BJD) at the mid-exposure time. barycorrpy
has a precision better than the <span class="math notranslate nohighlight">\(cm s^{-1}\)</span> level. We also estimate the maximum BERV value for this object
across the year. If for any reason the BERV calculation fails with barycorrpy we calculate an estimate of the BERV
(precise to <span class="math notranslate nohighlight">\(\sim 10 m s^{-1}\)</span>, modified from PyAstronomy.pyasl.baryvel; a python implementation of helcorr)
and flag that an estimated BERV correction was calculated. This estimated BERV is not precise enough for PRV work but
is sufficient to allow for acceptable telluric correction.</p>
</section>
<section id="leak-correction">
<h2>Leak Correction<a class="headerlink" href="#leak-correction" title="Permalink to this heading">¶</a></h2>
<p>For scientific observations, the reference fiber either has a DARK or an FP illuminating the pixels in this fiber.
For PRV an FP allows a simultaneous RV measurement of an FP alongside the measurement of the stellar RV; this allows
precise tracking of the instrumental drift when the simultaneous FP is compared to the <cite>FP_FP</cite> from the nightly
wavelength solution calibration. However, light from the FP has been shown to slightly contaminate the science fibers
and thus we provide a correction for such calibration.</p>
<p>During the reference sequence  many <cite>DARK_FP</cite> are combined (and extracted) to form a model of the light seen in the
science fibers when no light (other than the contribution from the DARK) was present as well as an extracted reference
fiber measurement of the FP flux that caused said contamination in the science fibers. Using these models, the
contamination measured in the science channels of the reference leak recipe is then scaled to the flux of the
simultaneous FP of the observation (using the extracted flux from this scientific observation we are trying to correct).
Then, this model is subtracted from the original science observation for each of the science fibers (AB or A or B),
order-by-order:</p>
<div class="math notranslate nohighlight">
\[ratio_{i} = \frac{\Sigma(L[C]_{i}S[C]_{i})}{\Sigma(S[C]_{i}^2)}\]</div>
<div class="math notranslate nohighlight">
\[scale_{i} = \frac{L[AB,A,B]_{i}}{ratio_{i}}\]</div>
<div class="math notranslate nohighlight">
\[S[AB,A,B]_{i,corr} = S[AB,A,B]_{i} - scale_{i}\]</div>
<p>where L[C] is the model of the FP from the leak reference recipe, S[C] is the 2D extracted spectrum in the reference
fiber (fiber C), L[AB,A,B] is the model of the contamination from the FP from the leak reference recipe in the science
fibers (either AB or A or B), S[AB,A,B] is the 2D extracted flux in the science fibers (either AB or A or B),
S[AB,A,B]_{corr} denotes the leak-corrected 2D extracted spectrum in the science fibers (either AB or A or B) and
i denotes that this is done order-by-order.</p>
</section>
<section id="thermal-correction">
<h2>Thermal correction<a class="headerlink" href="#thermal-correction" title="Permalink to this heading">¶</a></h2>
<p>The reference dark, applied during the standard image calibration phase, removes the high-frequency components of the
dark; however, the thermal contribution still remains (and varies on a night-by-night basis). For this reason, we use
nightly extracted <cite>DARK_DARK</cite> files to model the thermal contribution present in an observation during the night.
The thermal correction model comes in two flavors, one for science observations where we assume there is some sort of
continuum to the spectrum and telluric contamination as well as a small contribution arising from the Earth’s
atmosphere itself, and one for HC or FP extractions where these assumptions are not true.</p>
<p>In the case where we have a scientific observation, a <cite>DARK_DARK_TEL</cite> (where the calibration fiber sees the cold source
and the science fibers see the mirror covers) is used. The extracted <cite>DARK_DARK_TEL</cite>  is then median filtered with a
width of 101 pixels (on a per-order basis). This width was chosen to be big enough to capture large-scale structures
in the dark and not be significantly affected by readout noise. A fit is then made to the red most orders
(<span class="math notranslate nohighlight">\(&gt;2450 nm\)</span>) using only flux lower than 0.01 from a transmission spectrum from the Transmissions of the
AtmosPhere for AStromomical data tool (TAPAS) – i.e., a domain where transmission is basically zero. We assume that
we can safely use any flux with a transmission of order zero to scale the thermal background to this zero transmission
value.</p>
<div class="math notranslate nohighlight">
\[\begin{split}mask = \left\{ \begin{array}{cl}
1: &amp; TAPAS &lt; 0.01  \\
0: &amp; \text{otherwise} \\
\end{array} \right. \\\end{split}\]</div>
<div class="math notranslate nohighlight">
\[ratio = median\left( \frac{TT[AB,A,B,C]\times mask}{S[AB,A,B,C] \times mask} \right)\]</div>
<div class="math notranslate nohighlight">
\[S[AB,A,B,C]_{corr} = S[AB,A,B,C] - \frac{TT[AB,A,B,C]}{ratio}\]</div>
<p>where TAPAS is the TAPAS spectrum, TT[AB,A,B,C] is a nightly extracted <cite>DARK_DARK_TEL</cite> spectrum, S[AB,A,B,C] denotes
the 2D extracted spectrum prior to correction and <span class="math notranslate nohighlight">\(S[AB,A,B]_{corr}\)</span> denotes the thermally corrected 2D extracted
spectrum.</p>
<p>In the case where we have an HC or an FP observation, a <cite>DARK_DARK_INT</cite> (where all three fibers see only the cold source,
not the sky nor the mirror covers) is used. The extracted <cite>DARK_DARK_INT</cite> is then median filtered (again with a width
of 101 pixels on a per-order basis) and a fit is made using an envelope to measure the thermal background in the
reddest orders (<span class="math notranslate nohighlight">\(&gt;2450\, nm\)</span>). The envelope is constructed by using the flux below the 10th percentile (i.e.,
not in the HC or FP peaks). This is then converted into a ratio and scaled to the observation we are correcting.</p>
<div class="math notranslate nohighlight">
\[ratio = median\left( \frac{TI[AB,A,B,C]}{P_{10}(TI[AB,A,B,C])} \right)\]</div>
<div class="math notranslate nohighlight">
\[S[AB,A,B,C]_{corr} = S[AB,A,B,C] - \frac{TI[AB,A,B,C]}{ratio}\]</div>
<p>where <span class="math notranslate nohighlight">\(P_{10}\)</span> is the 10th percentile value, TI[AB,A,B,C] is a nightly extracted <cite>DARK_DARK_INT</cite> spectrum
(median filtered with a width of 101 pixels), S[AB,A,B,C] denotes the 2D extracted spectrum prior to correction and
<span class="math notranslate nohighlight">\(S[AB,A,B]_{corr}\)</span> denotes the thermally corrected 2D extracted spectrum.</p>
</section>
<section id="s1d-generation">
<h2>S1D generation<a class="headerlink" href="#s1d-generation" title="Permalink to this heading">¶</a></h2>
<p>The <cite>E2DS</cite> and <cite>E2DSFF</cite> formats are not necessarily the most convenient for science analysis, having duplicated
wavelength coverage at order overlap and slightly varying velocity sampling with each order and between orders.
We therefore transform the <cite>E2DSFF</cite> file into the <cite>S1D</cite> format. The <cite>S1D</cite> is sampled on a constant grid for all
objects. We have two differing <cite>S1D</cite> formats, one with a uniform step in wavelength (0.05 nm/pixel) and one with a
constant step in velocity (1 <span class="math notranslate nohighlight">\(km s^{-1}\)</span>/pixel), both being sampled between 965 nm and 2500 nm. Numerically,
to construct the <cite>S1D</cite>, we use as an input the <cite>E2DSFF</cite> file prior to blaze correction and the blaze file as inputs.
We create two <cite>S1D</cite> vectors, one corresponding to the total flux and one corresponding to the total blaze on the
destination wavelength grid. We use a 5th order polynomial spline to project the flux of a given order onto the flux
grid and perform the same operation with the blaze onto the weight vector. We do not consider the blaze below 20% of
the peak blaze value and values on the destination wavelength grids that are out of the order’s range are set to zero.
We loop through orders and sum the contribution of each order onto the respective destination grids for the <cite>E2DSFF</cite>
science flux and blaze. Note that the <cite>S1D</cite> generation only depends on the blaze calibration. As such any spectrum
(regardless of emission lines, low flux, or strong bands) can be converted to <cite>S1D</cite> format and we generate <cite>S1D</cite> for
<cite>HC_HC</cite> and <cite>FP_FP</cite> as well as science targets.</p>
</section>
</section>


            <div class="clearer"></div>
          </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">APERO 0.8.001 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Extraction</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, Neil Cook.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.0.1.
    </div>
  </body>
</html>